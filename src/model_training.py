# src/model_training.py

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import load_model, save_model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from src.hierarchical_model import HierarchicalTemporalModel
import logging

# Configuration du logging
logger = logging.getLogger('ModelTraining')
logger.setLevel(logging.INFO)

MODEL_DIR = "models/hierarchical"
os.makedirs(MODEL_DIR, exist_ok=True)

def train_hierarchical_model(symbol: str, multi_scale_data: dict):
    """Entra√Æne un mod√®le hi√©rarchique pour un symbole donn√©"""
    try:
        # V√©rifier les donn√©es disponibles
        if not multi_scale_data:
            logger.error(f"‚ùå Aucune donn√©e multi-√©chelle pour {symbol}")
            return
        
        # Pr√©parer les donn√©es d'entr√©e et cible
        X_train, y_train = {}, None
        input_shapes = {}
        
        for tf_name, (X, y, confidence) in multi_scale_data.items():
            if tf_name == "dynamic_weights":
                continue
                
            # Utiliser seulement les donn√©es avec suffisamment d'√©chantillons
            if len(X) > lookback * 2:  # Au moins 2 fen√™tres compl√®tes
                X_train[tf_name] = X
                input_shapes[tf_name] = X.shape[1:]
                
                # Prendre y de la timeframe la plus courte comme r√©f√©rence
                if y_train is None or tf_name == "1m":
                    y_train = y
        
        if not X_train or y_train is None:
            logger.warning(f"‚ö†Ô∏è Donn√©es insuffisantes pour {symbol}")
            return
        
        # Cr√©er et entra√Æner le mod√®le hi√©rarchique
        model = HierarchicalTemporalModel(input_shapes, X_train[list(X_train.keys())[0]].shape[-1])
        
        early_stop = EarlyStopping(
            monitor='val_loss', 
            patience=10, 
            restore_best_weights=True
        )
        
        checkpoint = ModelCheckpoint(
            os.path.join(MODEL_DIR, f"{symbol}_best.h5"),
            save_best_only=True,
            monitor='val_loss',
            mode='min'
        )
        
        # D√©terminer les param√®tres d'entra√Ænement adaptatifs
        min_samples = min([len(X) for X in X_train.values()])
        
        # Param√®tres adaptatifs
        epochs = min(100, max(20, min_samples // 100))
        batch_size = min(64, max(16, min_samples // 50))
        
        logger.info(f"Param√®tres adaptatifs: {epochs} epochs, batch_size={batch_size}")
        
        history = model.model.fit(
            list(X_train.values()),
            y_train,
            validation_split=0.2,
            epochs=epochs,
            batch_size=batch_size,
            callbacks=[early_stop, checkpoint],
            verbose=1
        )
        
        # Sauvegarder le mod√®le final
        model_path = os.path.join(MODEL_DIR, f"{symbol}.h5")
        save_model(model.model, model_path)
        logger.info(f"‚úÖ Mod√®le hi√©rarchique sauvegard√©: {model_path}")
        
        return model
    
    except Exception as e:
        logger.error(f"‚ùå Erreur entra√Ænement hi√©rarchique {symbol}: {e}")
        return None

def train_all_hierarchical_models(multi_scale_dataset: dict):
    """Entra√Æne les mod√®les hi√©rarchiques pour tous les symboles"""
    if not multi_scale_dataset:
        logger.error("‚ùå Aucune donn√©e disponible pour l'entra√Ænement hi√©rarchique")
        return
    
    logger.info(f"üöÄ D√©but de l'entra√Ænement des mod√®les hi√©rarchiques sur {len(multi_scale_dataset)} symboles")
    
    for symbol, multi_scale_data in multi_scale_dataset.items():
        try:
            logger.info(f"üß† Entra√Ænement hi√©rarchique pour {symbol}")
            train_hierarchical_model(symbol, multi_scale_data)
        except Exception as e:
            logger.error(f"‚ùå Erreur entra√Ænement hi√©rarchique {symbol}: {e}")

def load_hierarchical_model(symbol: str):
    """Charge un mod√®le hi√©rarchique sauvegard√©"""
    model_path = os.path.join(MODEL_DIR, f"{symbol}.h5")
    if os.path.exists(model_path):
        return HierarchicalTemporalModel.load(model_path)
    return None
